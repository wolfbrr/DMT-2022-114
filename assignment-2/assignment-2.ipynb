{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab796d9b",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cec730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def create_submission(test_data, property_predicted_score):\n",
    "    !mv submission.csv.zip prev.submission.zip\n",
    "    test_data['raiting'] = property_predicted_score\n",
    "    submition_data = test_data[['srch_id','prop_id','raiting']]\n",
    "    submition_data = submition_data.sort_values(by=['srch_id', 'raiting'], ascending=[True,  False])\n",
    "    submition_data = submition_data.drop(columns=\"raiting\")\n",
    "    submition_data.to_csv('submission.csv', index=False)\n",
    "    !zip submission.csv.zip  submission.csv\n",
    "    !rm submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8423ac",
   "metadata": {},
   "source": [
    "### load training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730774e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if loaded train file exists\n",
    "try:\n",
    "    with open('data/train-data.pickle', 'rb') as handle:\n",
    "        train = pickle.load(handle)\n",
    "#if not load and save\n",
    "except:\n",
    "    !unzip data/training_set_VU_DM.csv.zip\n",
    "    train = pd.read_csv('training_set_VU_DM.csv')\n",
    "    !rm training_set_VU_DM.csv\n",
    "    with open('data/train-data.pickle', 'wb') as handle:\n",
    "        pickle.dump(train, handle)\n",
    "\n",
    "#if loaded test file exists\n",
    "try:\n",
    "    with open('data/test-data.pickle', 'rb') as handle:\n",
    "        test = pickle.load(handle)\n",
    "#if not load and save\n",
    "except:\n",
    "    !unzip data/test_set_VU_DM.csv.zip\n",
    "    test = pd.read_csv('test_set_VU_DM.csv')\n",
    "    !rm test_set_VU_DM.csv\n",
    "    with open('data/test-data.pickle', 'wb') as handle:\n",
    "        pickle.dump(test, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb12627",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c746f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discountedCumulativeGain(result, k=5):\n",
    "    \"\"\"\n",
    "    Evaluated per query\n",
    "    taken from \n",
    "    https://towardsdatascience.com/normalized-discounted-cumulative-gain-37e6f75090e9\n",
    "    \"\"\"\n",
    "    dcg = []\n",
    "    for idx, val in enumerate(result[0:k]): \n",
    "        numerator = 2**val - 1\n",
    "        # add 2 because python 0-index\n",
    "        denominator =  np.log2(idx + 2) \n",
    "        score = numerator/denominator\n",
    "        dcg.append(score)\n",
    "    return sum(dcg)\n",
    "\n",
    "\n",
    "def NDCG_at_k(X, ranking, ideal_ranking, k=5):\n",
    "    #create df with a querry rating and ideal rating\n",
    "    df = X[['srch_id']]\n",
    "    df.loc[: ,'ranking'] = ranking\n",
    "    df.loc[: ,'true_ranking'] = ideal_ranking\n",
    "    df = df.sort_values(by=['srch_id', 'true_ranking'], ascending=[True,  False])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.groupby('srch_id').agg\\\n",
    "    (lambda x: discountedCumulativeGain(x, k))\n",
    "    x = df[df['true_ranking']!=0]\n",
    "    x = x['ranking']/x['true_ranking']\n",
    "    \n",
    "    return x.mean()\n",
    "    \n",
    "    \n",
    "def target_function(data_frame):\n",
    "    return data_frame['click_bool'] + data_frame['booking_bool']*4 #if booked then clicked booked = 5\n",
    "\n",
    "def features_engeneering(data_frame):\n",
    "    #normalise price_usd by country id\n",
    "    \n",
    "    mask_log_0 = data_frame['prop_log_historical_price'] == 0\n",
    "    data_frame[['historical_price']] = data_frame[['prop_log_historical_price']].applymap(np.exp)\n",
    "    data_frame.loc[mask_log_0, 'historical_price'] = data_frame.loc[mask_log_0, 'price_usd']\n",
    "\n",
    "    price_per_country_median = data_frame.groupby('prop_country_id').median().reset_index()\n",
    "    price_per_country_median = price_per_country_median[['prop_country_id','price_usd']]\n",
    "    \n",
    "    \n",
    "    price_per_country_median = price_per_country_median.rename(columns={\"price_usd\": \"price_per_country_median\"})\n",
    "    data_frame = data_frame.merge(price_per_country_median, left_on='prop_country_id', right_on='prop_country_id')\n",
    "    \n",
    "    # apply median to missing values in price_usd\n",
    "    mask = data_frame['price_usd']==0\n",
    "    data_frame.loc[mask, 'price_usd'] = data_frame.loc[mask, 'price_per_country_median']\n",
    "    mask = data_frame['historical_price']==0\n",
    "    data_frame.loc[mask, 'historical_price'] = data_frame.loc[mask, 'price_per_country_median']\n",
    "\n",
    "    # normalization\n",
    "    #data_frame['price_usd'] = data_frame['price_usd']/data_frame['price_per_country_median']\n",
    "    #data_frame['historical_price'] = data_frame['historical_price']/data_frame['price_per_country_median']\n",
    "\n",
    "    # normalise by number of persons\n",
    "    number_of_person = (data_frame['srch_adults_count'] + data_frame['srch_children_count']/2)\n",
    "    data_frame['price_per_person_per_night'] = data_frame['price_usd']/number_of_person/data_frame['srch_length_of_stay']\n",
    "    data_frame.loc[data_frame['prop_review_score'].isnull(),'prop_review_score'] = data_frame['prop_review_score'].median()\n",
    "    \n",
    "    #\n",
    "    #data standartization\n",
    "    \n",
    "    #for feature in ['prop_starrating','prop_location_score1']:\n",
    "    #    x = data_frame[feature].values\n",
    "    #    x = x.reshape(-1,1)\n",
    "    #    data_frame[feature] = normalize(x)\n",
    "    \n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def undersample(data_frame):\n",
    "    mask = data_frame['click_bool']==False\n",
    "    average_non_booked = data_frame[mask].groupby('srch_id').mean().reset_index()\n",
    "    \n",
    "     \n",
    "    #average_non_booked = input_data_frame[mask].sample(221879)\n",
    "     \n",
    "    data_frame = data_frame.drop(data_frame[mask].index)\n",
    "    data_frame = data_frame.reset_index()\n",
    "    #print('average non booked')\n",
    "    #display(average_non_booked)\n",
    "    data_frame = data_frame.append(average_non_booked)\n",
    "    data_frame = data_frame.sort_values(by=['srch_id'], ascending=[True])\n",
    "    #Fixing boolean values\n",
    "    for feature in ['random_bool', 'prop_brand_bool','promotion_flag','srch_saturday_night_bool' ]:\n",
    "        data_frame.loc[data_frame[feature]<0.5, feature] = False\n",
    "        data_frame.loc[data_frame[feature]>=0.5, feature] = True\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6c0eb",
   "metadata": {},
   "source": [
    "### Total columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474a3f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4958347"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0521ba",
   "metadata": {},
   "source": [
    "### Total null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367f65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id                              0\n",
      "date_time                            0\n",
      "site_id                              0\n",
      "visitor_location_country_id          0\n",
      "visitor_hist_starrating        4706481\n",
      "visitor_hist_adr_usd           4705359\n",
      "prop_country_id                      0\n",
      "prop_id                              0\n",
      "prop_starrating                      0\n",
      "prop_review_score                 7364\n",
      "prop_brand_bool                      0\n",
      "prop_location_score1                 0\n",
      "prop_location_score2           1090348\n",
      "prop_log_historical_price            0\n",
      "position                             0\n",
      "price_usd                            0\n",
      "promotion_flag                       0\n",
      "srch_destination_id                  0\n",
      "srch_length_of_stay                  0\n",
      "srch_booking_window                  0\n",
      "srch_adults_count                    0\n",
      "srch_children_count                  0\n",
      "srch_room_count                      0\n",
      "srch_saturday_night_bool             0\n",
      "srch_query_affinity_score      4640941\n",
      "orig_destination_distance      1607782\n",
      "random_bool                          0\n",
      "comp1_rate                     4838417\n",
      "comp1_inv                      4828788\n",
      "comp1_rate_percent_diff        4863908\n",
      "comp2_rate                     2933675\n",
      "comp2_inv                      2828078\n",
      "comp2_rate_percent_diff        4402109\n",
      "comp3_rate                     3424059\n",
      "comp3_inv                      3307357\n",
      "comp3_rate_percent_diff        4485550\n",
      "comp4_rate                     4650969\n",
      "comp4_inv                      4614684\n",
      "comp4_rate_percent_diff        4827261\n",
      "comp5_rate                     2735974\n",
      "comp5_inv                      2598327\n",
      "comp5_rate_percent_diff        4117248\n",
      "comp6_rate                     4718190\n",
      "comp6_inv                      4697371\n",
      "comp6_rate_percent_diff        4862173\n",
      "comp7_rate                     4642999\n",
      "comp7_inv                      4601925\n",
      "comp7_rate_percent_diff        4819832\n",
      "comp8_rate                     3041693\n",
      "comp8_inv                      2970844\n",
      "comp8_rate_percent_diff        4343617\n",
      "click_bool                           0\n",
      "gross_bookings_usd             4819957\n",
      "booking_bool                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89a0090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns not in both sets {'booking_bool', 'click_bool', 'position'}\n"
     ]
    }
   ],
   "source": [
    "train.loc[train['prop_review_score'].isnull(),'prop_review_score'] = train['prop_review_score'].median()\n",
    "\n",
    "df = train.dropna(axis=1)\n",
    "df[df['click_bool']==True]\n",
    "del train\n",
    "a = set(df.columns)\n",
    "b = set(test.columns)\n",
    "print(f'columns not in both sets {a-b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051dc3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03bbe0e5",
   "metadata": {},
   "source": [
    "### split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c055b3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = features_engeneering(df)\n",
    "#df = undersample(df)\n",
    "\n",
    "test = features_engeneering(test)\n",
    "\n",
    "#  the columns after droping\n",
    "#['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
    "#       'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score',\n",
    "#       'prop_brand_bool', 'prop_location_score1', 'prop_log_historical_price',\n",
    "#       'position', 'price_usd', 'promotion_flag', 'srch_destination_id',\n",
    "#       'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count',\n",
    "#       'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "#       'random_bool', 'click_bool', 'booking_bool', 'price_per_person']\n",
    " \n",
    "\n",
    "features_to_choose = ['prop_review_score',  \n",
    "                      'prop_starrating', \n",
    "                      'prop_brand_bool', \n",
    "                      'prop_location_score1',\n",
    "                      'srch_booking_window',\n",
    "                      'historical_price', #'prop_log_historical_price', #\n",
    "                      'promotion_flag', \n",
    "                      'srch_saturday_night_bool', \n",
    "                      'random_bool', \n",
    "                      'price_per_person_per_night']\n",
    "\n",
    "Y = target_function(df)\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(df, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17cda5",
   "metadata": {},
   "source": [
    "### hotels numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1114ad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7773"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test['prop_id']) ) #- len(set(df['prop_id']) )\n",
    "len(set(test['prop_id']) - set(df['prop_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mlxtend.frequent_patterns import apriori\n",
    "#from mlxtend.frequent_patterns import association_rules\n",
    "#frequent_itemsets= apriori(df[['promotion_flag','srch_saturday_night_bool', 'random_bool', 'click_bool', 'booking_bool']], min_support=0.07, use_colnames=True)\n",
    "#rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "#rules = rules.sort_values(by=[ 'support', 'confidence',], ascending=False)\n",
    "\n",
    "#rules[['antecedents', 'consequents','support','confidence']].iloc[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f539a",
   "metadata": {},
   "source": [
    "### Test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eddfdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of train fit: 692.6450707912445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfson/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_@5 0.0745877033442044\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import neighbors, linear_model\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\n",
    "# Fit regression model\n",
    "\n",
    "#model = linear_model.LinearRegression()\n",
    "#n_neighbors = 10\n",
    "#model = neighbors.KNeighborsRegressor(n_neighbors)\n",
    "#model= DecisionTreeRegressor(random_state=0)\n",
    "#model = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=5, random_state=0)\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "###########################################\n",
    "start = time.time()\n",
    "model.fit(X_train[features_to_choose], Y_train)\n",
    "end = time.time()\n",
    "print(\"The time of train fit:\", end-start)\n",
    "\n",
    "Y_pred = model.predict(X_test[features_to_choose])\n",
    "\n",
    "ndcg_score = NDCG_at_k(X_test, ranking=Y_pred,\\\n",
    "                       ideal_ranking=Y_test, k=5)\n",
    "#mae = mean_absolute_error(Y_test, Y_pred)\n",
    "#mse = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "#print(f'mae: {mae} mse: {mse}')\n",
    "print(f'ndcg_@5 {ndcg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e51eb",
   "metadata": {},
   "source": [
    "### Fit and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b879331a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_306506/2114707712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_to_choose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The time of final fit:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "model.fit(X[features_to_choose], Y)\n",
    "end = time.time()\n",
    "print(\"The time of final fit:\", end-start)\n",
    "\n",
    "raitings = model.predict(test[features_to_choose])\n",
    "create_submission(test, raitings)\n",
    "ndcg_score = NDCG_at_k(X_test, ranking=Y_pred,\\\n",
    "                       ideal_ranking=Y_test, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
