{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab796d9b",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cec730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def create_submission(test_data, property_predicted_score):\n",
    "    !mv submission.csv.zip prev.submission.zip\n",
    "    test_data['raiting'] = property_predicted_score\n",
    "    submition_data = test_data[['srch_id','prop_id','raiting']]\n",
    "    submition_data = submition_data.sort_values(by=['srch_id', 'raiting'], ascending=[True,  False])\n",
    "    submition_data = submition_data.drop(columns=\"raiting\")\n",
    "    submition_data.to_csv('submission.csv', index=False)\n",
    "    !zip submission.csv.zip  submission.csv\n",
    "    !rm submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8423ac",
   "metadata": {},
   "source": [
    "### load training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730774e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if loaded train file exists\n",
    "try:\n",
    "    with open('data/train-data.pickle', 'rb') as handle:\n",
    "        train = pickle.load(handle)\n",
    "#if not load and save\n",
    "except:\n",
    "    !unzip data/training_set_VU_DM.csv.zip\n",
    "    train = pd.read_csv('training_set_VU_DM.csv')\n",
    "    !rm training_set_VU_DM.csv\n",
    "    with open('data/train-data.pickle', 'wb') as handle:\n",
    "        pickle.dump(train, handle)\n",
    "\n",
    "#if loaded test file exists\n",
    "try:\n",
    "    with open('data/test-data.pickle', 'rb') as handle:\n",
    "        test = pickle.load(handle)\n",
    "#if not load and save\n",
    "except:\n",
    "    !unzip data/test_set_VU_DM.csv.zip\n",
    "    test = pd.read_csv('test_set_VU_DM.csv')\n",
    "    !rm test_set_VU_DM.csv\n",
    "    with open('data/test-data.pickle', 'wb') as handle:\n",
    "        pickle.dump(test, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb12627",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c746f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discountedCumulativeGain(result, k=5):\n",
    "    \"\"\"\n",
    "    Evaluated per query\n",
    "    taken from \n",
    "    https://towardsdatascience.com/normalized-discounted-cumulative-gain-37e6f75090e9\n",
    "    \"\"\"\n",
    "    dcg = []\n",
    "    for idx, val in enumerate(result[0:k]): \n",
    "        numerator = 2**val - 1\n",
    "        # add 2 because python 0-index\n",
    "        denominator =  np.log2(idx + 2) \n",
    "        score = numerator/denominator\n",
    "        dcg.append(score)\n",
    "    return sum(dcg)\n",
    "\n",
    "\n",
    "def NDCG_at_k(X, ranking, ideal_ranking, k=5):\n",
    "    #create df with a querry rating and ideal rating\n",
    "    df = X[['srch_id']]\n",
    "    df.loc[: ,('ranking')] = ranking\n",
    "    df.loc[: ,('true_ranking')] = ideal_ranking\n",
    "    \n",
    "    df = df.sort_values(by=['srch_id', 'true_ranking'], ascending=[True,  False])\n",
    "    INDCG  = df.groupby('srch_id').agg\\\n",
    "    (lambda x: discountedCumulativeGain(x, k))\n",
    "    x_true = INDCG[INDCG['true_ranking']!=0]\n",
    "\n",
    "    df = df.sort_values(by=['srch_id', 'ranking'], ascending=[True,  False])\n",
    "    NDCG  = df.groupby('srch_id').agg\\\n",
    "    (lambda x: discountedCumulativeGain(x, k))\n",
    "    x = NDCG[NDCG['true_ranking']!=0] # true ranking will be alwas zero if no booking/click was made\n",
    "\n",
    "    x = x['true_ranking']/x_true['true_ranking'] # true ranking has the information regarding actual booking\n",
    "    print(f'ndcg_@{k} {x.mean()}')\n",
    "\n",
    "    return x.mean()\n",
    "    \n",
    "    \n",
    "def target_function(data_frame):\n",
    "    return data_frame['click_bool'] + data_frame['booking_bool']*4 #if booked then clicked booked = 5\n",
    "\n",
    "def features_engeneering(data_frame):\n",
    "    #fill missing property review score by median over whole data\n",
    "    data_frame.loc[data_frame['prop_review_score'].isnull(),'prop_review_score'] = data_frame['prop_review_score'].median()\n",
    "\n",
    "    #normalise price_usd by country id\n",
    "    mask_log_0 = data_frame['prop_log_historical_price'] == 0\n",
    "    data_frame[['historical_price']] = data_frame[['prop_log_historical_price']].applymap(np.exp)\n",
    "    data_frame.loc[mask_log_0, 'historical_price'] = data_frame.loc[mask_log_0, 'price_usd']\n",
    "\n",
    "    price_per_country_median = data_frame.groupby('prop_country_id').median().reset_index()\n",
    "    price_per_country_median = price_per_country_median[['prop_country_id','price_usd']]\n",
    "    price_per_country_median = price_per_country_median.rename(columns={\"price_usd\": \"price_per_country_median\"})\n",
    "    data_frame = data_frame.merge(price_per_country_median, left_on='prop_country_id', right_on='prop_country_id')\n",
    "    # apply median to missing values in price_usd\n",
    "    mask = data_frame['price_usd']==0\n",
    "    data_frame.loc[mask, 'price_usd'] = data_frame.loc[mask, 'price_per_country_median']\n",
    "    mask = data_frame['historical_price']==0\n",
    "    data_frame.loc[mask, 'historical_price'] = data_frame.loc[mask, 'price_per_country_median']\n",
    "\n",
    "    # normalization\n",
    "    #data_frame['price_usd'] = data_frame['price_usd']/data_frame['price_per_country_median']\n",
    "    #data_frame['historical_price'] = data_frame['historical_price']/data_frame['price_per_country_median']\n",
    "\n",
    "    # normalise by number of persons\n",
    "    number_of_person = (data_frame['srch_adults_count'] + data_frame['srch_children_count']/2)\n",
    "    data_frame['price_per_person_per_night'] = data_frame['price_usd']/number_of_person/data_frame['srch_length_of_stay']\n",
    "    data_frame.loc[data_frame['prop_review_score'].isnull(),'prop_review_score'] = data_frame['prop_review_score'].median()\n",
    "    \n",
    "    #\n",
    "    #data standartization\n",
    "    \n",
    "    #for feature in ['prop_starrating','prop_location_score1']:\n",
    "    #    x = data_frame[feature].values\n",
    "    #    x = x.reshape(-1,1)\n",
    "    #    data_frame[feature] = normalize(x)\n",
    "    \n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def undersample(data_frame):\n",
    "    mask = data_frame['click_bool']==False\n",
    "    average_non_booked = data_frame[mask].groupby('srch_id').mean().reset_index()\n",
    "    \n",
    "    data_frame = data_frame.drop(data_frame[mask].index)\n",
    "    data_frame = data_frame.reset_index()\n",
    "\n",
    "    data_frame = data_frame.append(average_non_booked)\n",
    "    data_frame = data_frame.sort_values(by=['srch_id'], ascending=[True])\n",
    "    \n",
    "    #Fixing boolean values\n",
    "    for feature in ['random_bool', 'prop_brand_bool','promotion_flag','srch_saturday_night_bool' ]:\n",
    "        data_frame.loc[data_frame[feature]<0.5, feature] = False\n",
    "        data_frame.loc[data_frame[feature]>=0.5, feature] = True\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6c0eb",
   "metadata": {},
   "source": [
    "### Total columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474a3f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4958347"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0521ba",
   "metadata": {},
   "source": [
    "### Total null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367f65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id                              0\n",
      "date_time                            0\n",
      "site_id                              0\n",
      "visitor_location_country_id          0\n",
      "visitor_hist_starrating        4706481\n",
      "visitor_hist_adr_usd           4705359\n",
      "prop_country_id                      0\n",
      "prop_id                              0\n",
      "prop_starrating                      0\n",
      "prop_review_score                 7364\n",
      "prop_brand_bool                      0\n",
      "prop_location_score1                 0\n",
      "prop_location_score2           1090348\n",
      "prop_log_historical_price            0\n",
      "position                             0\n",
      "price_usd                            0\n",
      "promotion_flag                       0\n",
      "srch_destination_id                  0\n",
      "srch_length_of_stay                  0\n",
      "srch_booking_window                  0\n",
      "srch_adults_count                    0\n",
      "srch_children_count                  0\n",
      "srch_room_count                      0\n",
      "srch_saturday_night_bool             0\n",
      "srch_query_affinity_score      4640941\n",
      "orig_destination_distance      1607782\n",
      "random_bool                          0\n",
      "comp1_rate                     4838417\n",
      "comp1_inv                      4828788\n",
      "comp1_rate_percent_diff        4863908\n",
      "comp2_rate                     2933675\n",
      "comp2_inv                      2828078\n",
      "comp2_rate_percent_diff        4402109\n",
      "comp3_rate                     3424059\n",
      "comp3_inv                      3307357\n",
      "comp3_rate_percent_diff        4485550\n",
      "comp4_rate                     4650969\n",
      "comp4_inv                      4614684\n",
      "comp4_rate_percent_diff        4827261\n",
      "comp5_rate                     2735974\n",
      "comp5_inv                      2598327\n",
      "comp5_rate_percent_diff        4117248\n",
      "comp6_rate                     4718190\n",
      "comp6_inv                      4697371\n",
      "comp6_rate_percent_diff        4862173\n",
      "comp7_rate                     4642999\n",
      "comp7_inv                      4601925\n",
      "comp7_rate_percent_diff        4819832\n",
      "comp8_rate                     3041693\n",
      "comp8_inv                      2970844\n",
      "comp8_rate_percent_diff        4343617\n",
      "click_bool                           0\n",
      "gross_bookings_usd             4819957\n",
      "booking_bool                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17cda5",
   "metadata": {},
   "source": [
    "### Amount of hotels in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1114ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of hotels in test data 129438 \n",
      "Amount of hotels in train data 129113\n",
      "Amount of uniqe hotels in train and not in test 7773\n"
     ]
    }
   ],
   "source": [
    "x = test['prop_id']\n",
    "print(f'Amount of hotels in test data {len(set(x))} ')\n",
    "y = train['prop_id']\n",
    "print(f'Amount of hotels in train data {len(set(y))}')\n",
    "print(f'Amount of uniqe hotels in train and not in test {len(set(x) - set(y))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a0090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = features_engeneering(train)\n",
    "test = features_engeneering(test)\n",
    "df = train.dropna(axis=1)\n",
    "del train\n",
    "\n",
    "a = set(df.columns)\n",
    "b = set(test.columns)\n",
    "print(f'columns not in both sets {a-b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbe0e5",
   "metadata": {},
   "source": [
    "### Choose features to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055b3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  the columns after droping\n",
    "#['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
    "#       'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score',\n",
    "#       'prop_brand_bool', 'prop_location_score1', 'prop_log_historical_price',\n",
    "#       'position', 'price_usd', 'promotion_flag', 'srch_destination_id',\n",
    "#       'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count',\n",
    "#       'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "#       'random_bool', 'click_bool', 'booking_bool', 'price_per_person']\n",
    " \n",
    "\n",
    "features_to_choose = ['prop_review_score',  \n",
    "                      'prop_starrating', \n",
    "                      'prop_brand_bool', \n",
    "                      'prop_location_score1',\n",
    "                      'srch_booking_window',\n",
    "                      'historical_price', #'prop_log_historical_price', #\n",
    "                      'promotion_flag', \n",
    "                      'srch_saturday_night_bool', \n",
    "                      'random_bool', \n",
    "                      'price_per_person_per_night']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mlxtend.frequent_patterns import apriori\n",
    "#from mlxtend.frequent_patterns import association_rules\n",
    "#frequent_itemsets= apriori(df[['promotion_flag','srch_saturday_night_bool', 'random_bool', 'click_bool', 'booking_bool']], min_support=0.07, use_colnames=True)\n",
    "#rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "#rules = rules.sort_values(by=[ 'support', 'confidence',], ascending=False)\n",
    "\n",
    "#rules[['antecedents', 'consequents','support','confidence']].iloc[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f539a",
   "metadata": {},
   "source": [
    "### Test and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfdbbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Fit regression model\n",
    "#model = linear_model.LinearRegression()\n",
    "#n_neighbors = 10\n",
    "#model = neighbors.KNeighborsRegressor(n_neighbors)\n",
    "#model= DecisionTreeRegressor(random_state=0)\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "########        EVALUATION           ###############\n",
    "X_train = df.iloc[0:int(len(df)/2), :]\n",
    "X_test = df.iloc[int(len(df)/2):, :]\n",
    "start = time.time()\n",
    "\n",
    "#X_train = undersample(X_train)\n",
    "\n",
    "model.fit(X_train[features_to_choose], target_function(X_train))\n",
    "end = time.time()\n",
    "print(\"The time of evaluation fit:\", end-start)\n",
    "\n",
    "Y_evaluation = model.predict(X_test[features_to_choose])\n",
    "Y_ideal = target_function(X_test)\n",
    "\n",
    "ndcg_score = NDCG_at_k(X_test, ranking=Y_evaluation, ideal_ranking=Y_ideal, k=5)\n",
    "# in submissioned version was 0.25193  that was evaluated here as 0.6472178554938205\n",
    "#test ndcg function\n",
    "#ndcg_score = NDCG_at_k(X_test, ranking=Y_ideal, ideal_ranking=Y_ideal, k=5)\n",
    "#assert ndcg_score == 1, \"Houston we've got a problem, Ideal ranking is not 1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e51eb",
   "metadata": {},
   "source": [
    "### Fit and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(df[features_to_choose], target_function(df))\n",
    "end = time.time()\n",
    "print(\"The time of final fit:\", end-start)\n",
    "raitings = model.predict(test[features_to_choose])\n",
    "create_submission(test, raitings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
