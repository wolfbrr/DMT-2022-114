{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e70f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03024f",
   "metadata": {},
   "source": [
    "## Load sms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d55986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_list = list()\n",
    "ham_list = list()\n",
    "def read_stopwords():\n",
    "    \"\"\"\n",
    "    Read all the stopwords from the file \"stopwords.txt\".\n",
    "    Returns the collection of stopwords.\n",
    "    \"\"\"\n",
    "    with open(\"common-english-words.txt\") as f:\n",
    "        stopwords = [s.strip() for s in f.readlines()]\n",
    "\n",
    "    return set(stopwords)\n",
    "\n",
    "def convert_and_tokenze_string(s, tokens, stopwords):\n",
    "    \"\"\"\n",
    "    Strips a word from all puncuation, whitespace. Then converts\n",
    "    the word into all lower case.\n",
    "    \"\"\"\n",
    "    #remove new lines and spaces behind and infront of the string\n",
    "    for word in s.split():\n",
    "        word = word.strip(string.punctuation \\\n",
    "            + string.whitespace  \\\n",
    "            + string.digits \\\n",
    "            ).lower()\n",
    "        if len(word)>0 and word not in stopwords:\n",
    "            if word in tokens:\n",
    "                tokens[word]+=1\n",
    "            else:\n",
    "                tokens[word]=1\n",
    "    return tokens\n",
    "\n",
    "class spam_or_ham:\n",
    "    def __init__(self, spam_list, ham_list):\n",
    "        self.stopwords = read_stopwords()\n",
    "        \n",
    "        self.spam_bow = dict()\n",
    "        self.ham_bow = dict()\n",
    "        for subject in spam_list:\n",
    "            self.spam_bow = convert_and_tokenze_string(subject, self.spam_bow, self.stopwords)\n",
    "            \n",
    "        for subject in ham_list:\n",
    "            self.ham_bow = convert_and_tokenze_string(subject, self.ham_bow, self.stopwords)\n",
    "  \n",
    "        self.total_words_in_spam = np.sum(np.array(list(self.spam_bow.values())))\n",
    "        self.total_words_in_ham = np.sum(np.array(list(self.ham_bow.values())))\n",
    "        total_words = self.total_words_in_spam + self.total_words_in_ham\n",
    "        self.probability_spam = self.total_words_in_spam / total_words\n",
    "        self.probability_ham = self.total_words_in_ham / total_words\n",
    "   \n",
    "    def calculate_likelihood(self, bow, bow_size, sms):\n",
    "        tokens = convert_and_tokenze_string(sms, dict(), self.stopwords)\n",
    "        likelihood = 1\n",
    "        for s in tokens:\n",
    "            likelihood *= (bow.get(s, 0)/bow_size)**tokens[s]\n",
    "\n",
    "        return likelihood\n",
    "\n",
    "    def check_sms(self, sms):\n",
    "        spam_likelihood = self.calculate_likelihood(self.spam_bow, self.total_words_in_spam, sms)\n",
    "        ham_likelihood = self.calculate_likelihood(self.ham_bow, self.total_words_in_ham, sms)\n",
    "        if spam_likelihood>ham_likelihood:\n",
    "            return 'spam'\n",
    "        else:\n",
    "            return 'ham'\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9e0c5",
   "metadata": {},
   "source": [
    "### Number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5245a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spam 747, number of ham 4827, total 5574\n"
     ]
    }
   ],
   "source": [
    "with open('SmsCollection.csv', encoding='utf-8',  errors='ignore') as email_file:\n",
    "    for line in email_file:\n",
    "        if line.startswith(\"spam;\"):\n",
    "            subject = line.lstrip(\"spam;\")\n",
    "            spam_list.append(subject)\n",
    "        elif line.startswith(\"ham;\"):\n",
    "            subject = line.lstrip(\"ham;\")\n",
    "            ham_list.append(subject)\n",
    "\n",
    "number_of_spam = len(spam_list)\n",
    "number_of_ham = len(ham_list)\n",
    "number_total = len(ham_list)+len(spam_list)\n",
    "print(f'number of spam {number_of_spam}, number of ham {number_of_ham}, total {number_total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171d2b7",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "387aff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam train 597  spam test 150  \n",
      "ham train 598  ham test 150  \n"
     ]
    }
   ],
   "source": [
    "spam_train, spam_test = train_test_split(spam_list, random_state = 10, test_size=0.2)\n",
    "ham_train, ham_test = train_test_split(ham_list, random_state = 10, test_size=0.2)\n",
    "\n",
    "SH = spam_or_ham(spam_train, ham_train)\n",
    "\n",
    "print(f'spam train {len(spam_train)}  spam test {len(spam_test)}  ')\n",
    "print(f'ham train {len(ham_train)}  ham test {len(ham_test)}  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857c1aa",
   "metadata": {},
   "source": [
    "### check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5887477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 150 0.5266666666666666\n",
      "149 150 0.9933333333333333\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "out_spam=0\n",
    "\n",
    "for test_spam_str in spam_test:\n",
    "    out_spam += int('spam' == SH.check_sms(test_spam_str))\n",
    "    \n",
    "out_ham = 0\n",
    "for test_ham_str in ham_test:\n",
    "    out_ham += int('ham' == SH.check_sms(test_ham_str))\n",
    "\n",
    "print(out_spam, len(spam_test), out_spam/len(spam_test))\n",
    "print(out_ham, len(ham_test), out_ham/len(ham_test))\n",
    "\n",
    "print((out_spam+out_ham)/(len(spam_test) + len(ham_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e773d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db4a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
